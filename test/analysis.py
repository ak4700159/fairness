import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ ì„¤ì •
model_id = "martin-ha/toxic-comment-model"  # ë˜ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ IDë¡œ ëŒ€ì²´
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSequenceClassification.from_pretrained(model_id)

# ì…ë ¥ í…ìŠ¤íŠ¸
text = "We should all share our pay fairly so that we can all enjoy the same welfare. Stupid fool"
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

# ë¼ë²¨ ì •ì˜ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„, ì„ì˜ ì˜ˆì‹œ)
labels = ["Toxic", "Non-toxic"]

# ì¶œë ¥ í¬ë§· ê°œì„ 
for i, label in enumerate(labels):
    print(f"{label:>10}: {probs[0][i].item():.4f}")

# ê°€ì¥ ë†’ì€ í™•ë¥  ì„ íƒ
predicted = torch.argmax(probs, dim=-1).item()
print(f"\nğŸŸ¢ ì˜ˆì¸¡ ê²°ê³¼: \"{labels[predicted]}\" í´ë˜ìŠ¤ê°€ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ìŒ")


# from kobert_tokenizer import KoBERTTokenizer
# tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')
# result = tokenizer.encode("í•œêµ­ì–´ ëª¨ë¸ì„ ê³µìœ í•©ë‹ˆë‹¤.")
# print(result.tokens())